{
    "cells": [
        {
            "metadata": {
                "collapsed": true
            },
            "cell_type": "markdown",
            "source": "# Introduction \n### New York City, one of the most vibrant financial centers of the United States, is home to thousands of restaurants\u2014each as diverse and unique as the 8.6 million people people who live there.  Every business in the city strives to rise above competitors while meeting strict city codes and laws.  Such a contentious environments demands that potential restaurant owners thoroughly consider many details before opening their businesses.  Considerations include a myriad of things to consider: cuisine, location, atmosphere, and customer-base. "
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Business Problem\n### As outlined above, future New York restaurant owners compete in a highly contentious business environment.  Therefore, this analysis seeks to capture and present accurate picture of some of the most successful restaurants in New York City. "
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# This review will provide an in-depth examination of the following factors to enable the target audience with all the data needed to confidently make an informed decision:\n### o Demographics of New York\n### o Population distributions\n### o Neighborhood statistics\n### o Avoidance areas, such as those cornered by competitors\n### o Independent markets, such as open markets and farmer\u2019s co-ops\n### o Local attractions including malls, tourist attractions, theaters, etc.\n\n# Target Audience\n### The target audience for this project primarily represents three types of people, entrepreneurs, professional restaurant staff, and investors.  This analysis will use modern data science principles to provide a well-researched recommendation to each of these groups.  \n\n# Data Sources\n### Though this review utilizes multiple sources, all data will focus on New York City:\n\n### - Geographical data comes from GPS-coordinates.org and NYC.gov\nhttps://gps-coordinates.org/new-york-city-latitude.php\nhttps://www1.nyc.gov/site/planning/zoning/districts-tools/residence-districts-r1-r10.page\n\n### - Primarily our base data search began on Wikipedia, at the following sites\nhttps://en.wikipedia.org/wiki/New_York_City\nhttps://en.wikipedia.org/wiki/List_of_restaurants_in_New_York_City\nhttps://en.wikipedia.org/wiki/New_York_City#Cuisine\nhttps://en.wikipedia.org/wiki/Economy_of_New_York_City\nhttps://en.wikipedia.org/wiki/New_York_City#Streets_and_highways\n\n### - Derived data covers over 300 neighborhoods and 5 boroughs\nhttps://geo.nyu.edu/?f%5Bdc_subject_sm%5D%5B%5D=Neighborhoods\n\n\n### - Restaurant is provided by City-data.com \nhttps://www.city-data.com/city/New-York-New-York.html\n\n### - Locations of sidewalk cafes and open-air eating establishment\nhttps://data.cityofnewyork.us/City-Government/Sidewalk-Caf-Regulations-GIS-Shapefile/qsuf-mgjh"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!conda install -c conda-forge geopy --yes",
            "execution_count": null,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Solving environment: \\ ",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!conda install -c conda-forge folium=0.5.0 --yes",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Downloading needed depecencies..."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import numpy as np \n\nimport pandas as pd \npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json \n\nfrom geopy.geocoders import Nominatim \n\nimport requests \nfrom pandas.io.json import json_normalize \n\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\nimport folium \n\nimport csv\n\nprint('Libraries imported.')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Methodology\n### This analysis uses mapping and table data to depict very detailed data visually.  Data was transformed with Pandas dataframe, then looped though the dataframe to render readable results. I then verified that predicted results were matching expeccted data.  Trained data and test data matched appropriately.  Then,  I created a map overlay showing New York Neighborhoods.  I used web scraping techniques, via Python/Beautiful Soup, to glean population and demographic data.  The project reqired several rounds of web scraping.  To clean data, I had to remove white spaces and change the name of some columns to make them usable.  When this portion of the project was complete, I saved the dataframe to a .CSV file.  Then, I downloaded and analyzed data related to New York cuisine.  Next I segmented and clustered neighborhoods with Foursquare API.  Then, I used k-means to cluster neighborhoods.  Lastly, I configured parameters to visualize the data in this report."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!wget -q -O 'newyork_data.json' https://ibm.box.com/shared/static/fbpwbovar7lf8p5sgddm06cgipa2rxpe.json\nprint('Data downloaded!')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "with open('newyork_data.json') as json_data:\n    newyork_data = json.load(json_data)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "neighborhoods_data = newyork_data['features']",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "neighborhoods_data[0]",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Pushing data through the Pandas dataframe"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "column_names = ['Borough', 'Neighborhood', 'Latitude', 'Longitude'] \n\nneighborhoods = pd.DataFrame(columns=column_names)\nneighborhoods",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "## Looping the data",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "for data in neighborhoods_data:\n    borough = neighborhood_name = data['properties']['borough'] \n    neighborhood_name = data['properties']['name']\n        \n    neighborhood_latlon = data['geometry']['coordinates']\n    neighborhood_lat = neighborhood_latlon[1]\n    neighborhood_lon = neighborhood_latlon[0]\n    \n    neighborhoods = neighborhoods.append({'Borough': borough,\n                                          'Neighborhood': neighborhood_name,\n                                          'Latitude': neighborhood_lat,\n                                          'Longitude': neighborhood_lon}, ignore_index=True)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "neighborhoods.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "neighborhoods.to_csv('BON1_NYC_GEO.csv',index=False)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Using GeoPy library to get ltitude and longitude coordinates for our city "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "address = 'New York City, NY'\n\ngeolocator = Nominatim(user_agent=\"Jupyter\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of New York City are {}, {}.'.format(latitude, longitude))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Creating our map overlayto depict neighborhoods"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "map_NewYork = folium.Map(location=[latitude, longitude], zoom_start=10)\n\nfor lat, lng, borough, neighborhood in zip(neighborhoods['Latitude'], neighborhoods['Longitude'], neighborhoods['Borough'], neighborhoods['Neighborhood']):\n    label = '{}, {}'.format(neighborhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_NewYork)  \n    \nmap_NewYork",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Here, we begin web scraping for population data "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "website_url = requests.get('https://en.wikipedia.org/wiki/Demographics_of_New_York_City').text\nsoup = BeautifulSoup(website_url,'lxml')\ntable = soup.find('table',{'class':'wikitable sortable'})\n\nheaders = [header.text for header in table.find_all('th')]\n\ntable_rows = table.find_all('tr')        \nrows = []\nfor row in table_rows:\n   td = row.find_all('td')\n   row = [row.text for row in td]\n   rows.append(row)\n\nwith open('BON2_POPULATION1.csv', 'w') as f:\n   writer = csv.writer(f)\n   writer.writerow(headers)\n   writer.writerows(row for row in rows if row)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Pop_data=pd.read_csv('BON2_POPULATION1.csv')\nPop_data.drop(Pop_data.columns[[9,10,11]], axis=1,inplace=True)\nprint('Data downloaded!')\nPop_data.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Pop_data.columns = Pop_data.columns.str.replace(' ', '')\nPop_data.columns = Pop_data.columns.str.replace('\\'','')\nPop_data.rename(columns={'Borough':'persons_sq_mi','County':'persons_sq_km'}, inplace=True)\nPop_data.head(10)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Pop_data.rename(columns = {'NewYorkCitysfiveboroughsvte\\n' : 'Borough',\n                   'Jurisdiction\\n':'County',\n                   'Population\\n':'Estimate_2017', \n                   'Landarea\\n':'square_miles',\n                    'Density\\n':'square_km',\n                          }, inplace=True)\nPop_data",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Pop_data['Borough']=Pop_data['Borough'].replace(to_replace='\\n', value='', regex=True)\nPop_data['County']=Pop_data['County'].replace(to_replace='\\n', value='', regex=True)\nPop_data['Estimate_2017']=Pop_data['Estimate_2017'].replace(to_replace='\\n', value='', regex=True)\nPop_data['square_miles']=Pop_data['square_miles'].replace(to_replace='\\n', value='', regex=True)\nPop_data['square_km']=Pop_data['square_km'].replace(to_replace='\\n', value='', regex=True)\nPop_data['persons_sq_mi']=Pop_data['persons_sq_mi'].replace(to_replace='\\n', value='', regex=True)\nPop_data['squarekm']=Pop_data['squarekm'].replace(to_replace='\\n', value='', regex=True)\nPop_data",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Pop_data.loc[5:,['persons_sq_mi','persons_sq_km']] = Pop_data.loc[2:,['persons_sq_mi','persons_sq_km']].shift(1,axis=1)\nPop_data.loc[5:,['square_km','persons_sq_mi']] = Pop_data.loc[2:,['square_km','persons_sq_mi']].shift(1,axis=1)\nPop_data.loc[5:,['square_miles','square_km']] = Pop_data.loc[2:,['square_miles','square_km']].shift(1,axis=1)\nPop_data.loc[5:,['Estimate_2017','square_miles']] = Pop_data.loc[2:,['Estimate_2017','square_miles']].shift(1,axis=1)\nPop_data.loc[5:,['County','Estimate_2017']] = Pop_data.loc[2:,['County','Estimate_2017']].shift(1,axis=1)\nPop_data.loc[5:,['Borough','County']] = Pop_data.loc[2:,['Borough','County']].shift(1,axis=1)\nPop_data",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Pop_data = Pop_data.fillna('')\nPop_data",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "i = Pop_data[((Pop_data.County == 'Sources: [2] and see individual borough articles'))].index\nPop_data.drop(i)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Pop_data.to_csv('BON2_POPULATION.csv',index=False)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "## Here, we draw demographics data through web scraping",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "website_url = requests.get('https://en.wikipedia.org/w/index.php?title=New_York_City&oldid=861524529').text\nsoup = BeautifulSoup(website_url,'lxml')\ntable = soup.find('table',{'class':'wikitable sortable collapsible'})\n\nheaders = [header.text for header in table.find_all('th')]\n\ntable_rows = table.find_all('tr')        \nrows = []\nfor row in table_rows:\n    td = row.find_all('td')\n    row = [row.text for row in td]\n    rows.append(row)\n\nwith open('NYC_DEMO.csv', 'w') as f:\n    writer = csv.writer(f)\n    writer.writerow(headers)\n    writer.writerows(row for row in rows if row)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Demo_data=pd.read_csv('NYC_DEMO.csv')\nprint('Data downloaded!')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Demo_data",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Demo_data.columns",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Demo_data.rename(columns = {'2010[239]' : '2010',\n                   '1990[241]':'1990',\n                   '1970[241]':'1970', \n                   '1940[241]\\n':'1940',\n                    }, inplace=True)\nDemo_data",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Demo_data.columns",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Demo_data.columns = Demo_data.columns.str.replace(' ', '')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Demo_data= Demo_data.replace('\\n',' ', regex=True)\nDemo_data",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Demo_data['1970'] = Demo_data['1970'].str.rstrip('[242]')\nDemo_data",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Demo_data.to_csv('BON2_DEMOGRAPHICS.csv',index=False)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from PIL import Image",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "%matplotlib inline\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nmpl.style.use('ggplot')\n\nprint ('Matplotlib version: ', mpl.__version__)\n\nfrom wordcloud import WordCloud, STOPWORDS\n\nprint ('Wordcloud is installed and imported!')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!conda install -c conda-forge wordcloud==1.4.1 --yes\n<div class=\"div-col columns column-width\" style=\"-moz-column-width: 30em; -webkit-column-width: 30em; column-width: 30em;\">\n<ul><li><a href=\"/wiki/Bedford_Park,_Bronx\" title=\"Bedford Park, Bronx\">Bedford Park</a> \u2013 Mexican, Puerto Rican, Dominican, Korean (on 204th St.)</li>\n<li><a href=\"/wiki/Belmont,_Bronx\" title=\"Belmont, Bronx\">Belmont</a> \u2013 Italian, Albanian (also known as \"Arthur Avenue,\" \"Little Italy\")</li>\n<li><a href=\"/wiki/City_Island,_Bronx\" title=\"City Island, Bronx\">City Island</a> \u2013 Italian, Seafood</li>\n<li><a href=\"/wiki/Morris_Park,_Bronx\" title=\"Morris Park, Bronx\">Morris Park</a> \u2013 Italian, Albanian</li>\n<li><a href=\"/wiki/Norwood,_Bronx\" title=\"Norwood, Bronx\">Norwood</a> \u2013 Filipino (formerly Irish, less so today)</li>\n<li><a href=\"/wiki/Riverdale,_Bronx\" title=\"Riverdale, Bronx\">Riverdale</a> \u2013 Jewish</li>\n<li><a href=\"/wiki/South_Bronx\" title=\"South Bronx\">South Bronx</a> \u2013 Puerto Rican, Dominican</li>\n<li><a href=\"/wiki/Wakefield,_Bronx\" title=\"Wakefield, Bronx\">Wakefield</a> \u2013 Jamaican, West Indian</li>\n<li><a href=\"/wiki/Woodlawn,_Bronx\" title=\"Woodlawn, Bronx\">Woodlawn</a> \u2013 Irish</li></ul>\n </div>",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "website_url = requests.get('https://en.wikipedia.org/wiki/Cuisine_of_New_York_City').text\nsoup = BeautifulSoup(website_url,'lxml')\nuls = soup.find({'div':'div-col columns column-width'})\n\nheaders = [header.text for header in ul.find_all('li')]\n\ntable_rows = ul.find_all('li')        \nlis = []\nfor ul in uls:\n    for li in ul.findAll('li'):\n        if li.find('ul'):\n            break\n        lis.append(li)\n\nwith open('BON3_NYC_CUISINE.csv', 'w') as f:\n    writer = csv.writer(f)\n    writer.writerow(headers)\n    writer.writerows(li for li in uls if li)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "my_file = project.get_file(\"BON3_NYC_CUISINE.csv\")\n\nmy_file.seek(0)\nimport pandas as pd\nNYC_CUISINE=pd.read_csv(\"BON3_NYC_CUISINE.csv\")\nNYC_CUISINE.drop(NYC_CUISINE.columns[[3,4,5,6,7]], axis=1,inplace=True) \nNYC_CUISINE.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "NYC_CUISINE.shape",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "NYC_CUISINE['Borough'].value_counts().to_frame()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "CUISINE_WC = NYC_CUISINE[['Cuisine']]\nCUISINE_WC",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "CUISINE_WC.to_csv('CUISINE_WC.txt', sep=',', index=False)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "CUISINE_WC1 = open('CUISINE_WC.txt', 'r').read()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "stopwords = set(STOPWORDS)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "NYC_CUISINE_WC = WordCloud(\n    background_color='white',\n    max_words=2000,\n    stopwords=stopwords\n)\n\nNYC_CUISINE_WC.generate(CUISINE_WC1)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "plt.imshow(NYC_CUISINE_WC, interpolation='bilinear')\nplt.axis('off')\n\nfig = plt.figure()\nfig.set_figwidth(30)\nfig.set_figheight(45)\n\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Brooklyn_data = NYC_CUISINE[NYC_CUISINE['Borough'] == 'Brooklyn'].reset_index(drop=True)\nBrooklyn_data.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BR_CUISINE_WC = Brooklyn_data[['Cuisine']]\nBR_CUISINE_WC",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BR_CUISINE_WC.to_csv('BR_CUISINE.txt', sep=',', index=False)\nBR_CUISINE_WC = open('BR_CUISINE.txt', 'r').read()\nstopwords = set(STOPWORDS)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BR_CUISINE_NYC = WordCloud(\n    background_color='white',\n    max_words=2000,\n    stopwords=stopwords\n)\n\nBR_CUISINE_NYC.generate(BR_CUISINE_WC)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "plt.imshow(BR_CUISINE_NYC, interpolation='bilinear')\nplt.axis('off')\n\nfig = plt.figure()\nfig.set_figwidth(30)\nfig.set_figheight(45)\n\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Queens_data = NYC_CUISINE[NYC_CUISINE['Borough'] == 'Queens'].reset_index(drop=True)\nQueens_data.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Q_CUISINE_WC = Queens_data[['Cuisine']]\nQ_CUISINE_WC",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Q_CUISINE_WC.to_csv('Q_CUISINE.txt', sep=',', index=False)\n\nQ_CUISINE_WC = open('Q_CUISINE.txt', 'r').read()\n\nstopwords = set(STOPWORDS)\n\nQ_CUISINE_NYC = WordCloud(\n    background_color='white',\n    max_words=2000,\n    stopwords=stopwords\n)\n\nQ_CUISINE_NYC.generate(Q_CUISINE_WC)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "plt.imshow(Q_CUISINE_NYC, interpolation='bilinear')\nplt.axis('off')\n\nfig = plt.figure()\nfig.set_figwidth(30)\nfig.set_figheight(45)\n\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Manhattan_data = NYC_CUISINE[NYC_CUISINE['Borough'] == 'Manhattan'].reset_index(drop=True)\nManhattan_data.head()\nMN_CUISINE_WC = Manhattan_data[['Cuisine']]\nMN_CUISINE_WC",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "MN_CUISINE_WC.to_csv('MN_CUISINE.txt', sep=',', index=False)\n\nMN_CUISINE_WC = open('MN_CUISINE.txt', 'r').read()\n\nstopwords = set(STOPWORDS)\n\nMN_CUISINE_NYC = WordCloud(\n    background_color='white',\n    max_words=2000,\n    stopwords=stopwords\n)\n\nMN_CUISINE_NYC.generate(MN_CUISINE_WC)\n\n<wordcloud.wordcloud.WordCloud at 0x7f562c126c50>\n\nplt.imshow(MN_CUISINE_NYC, interpolation='bilinear')\nplt.axis('off')\n\nfig = plt.figure()\nfig.set_figwidth(30)\nfig.set_figheight(45)\n\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Bronx_data = NYC_CUISINE[NYC_CUISINE['Borough'] == 'The Bronx'].reset_index(drop=True)\nBronx_data.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BX_CUISINE_WC = Bronx_data[['Cuisine']]\nBX_CUISINE_WC",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BX_CUISINE_WC.to_csv('BX_CUISINE.txt', sep=',', index=False)\n\nBX_CUISINE_WC = open('BX_CUISINE.txt', 'r').read()\n\nstopwords = set(STOPWORDS)\n\nBX_CUISINE_NYC = WordCloud(\n    background_color='white',\n    max_words=2000,\n    stopwords=stopwords\n)\n\nBX_CUISINE_NYC.generate(BX_CUISINE_WC)\n\n<wordcloud.wordcloud.WordCloud at 0x7f562c149438>\n\nplt.imshow(BX_CUISINE_NYC, interpolation='bilinear')\nplt.axis('off')\n\nfig = plt.figure()\nfig.set_figwidth(30)\nfig.set_figheight(45)\n\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import seaborn as sns",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "my_file = project.get_file(\"DOHMH_Farmers_Markets_and_Food_Boxes.csv\")\n\nmy_file.seek(0)\nFM_NYC=pd.read_csv(my_file)\nFM_NYC.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "FM_NYC.rename(columns={'Service Type':'Service_Type'}, inplace=True)\nprint(FM_NYC.Service_Type.unique())\nFM_NYC['Service_Type'].value_counts().to_frame()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "fig.ax = plt.subplots(1, 1, figsize=(5, 5))\nsns.countplot(x='Service_Type',data=FM_NYC)\nax.set_title(\"Service_Type\")\nfor t in ax.patches:\n    if (np.isnan(float(t.get_height()))):\n        ax.annotate('', (t.get_x(), 0))\n    else:\n        ax.annotate(str(format(int(t.get_height()), ',d')), (t.get_x(), t.get_height()*1.01))\n    \nplt.show();",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "FM_NYC_filtered = FM_NYC[FM_NYC['Service_Type'] == 'Farmers Markets'].copy()\nFM_NYC_filtered ['Borough'] = FM_NYC_filtered['Borough'].map(lambda x: x.strip())\nprint(FM_NYC_filtered.shape)\nFM_NYC_filtered.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "fig.ax = plt.subplots(1, 1, figsize=(5, 5))\nsns.countplot(x='Borough',data=FM_NYC_filtered)\nax.set_title(\"Borough\")\nfor t in ax.patches:\n    if (np.isnan(float(t.get_height()))):\n        ax.annotate('', (t.get_x(), 0))\n    else:\n        ax.annotate(str(format(int(t.get_height()), ',d')), (t.get_x(), t.get_height()*1.01))\n        ax.set_xticklabels([t.get_text().split(\"T\")[0] for t in ax.get_xticklabels()])\n\nplt.xticks(rotation=90) \nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "address = 'New York City, NY'\n\ngeolocator = Nominatim(user_agent=\"Jupyter\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of New York City are {}, {}.'.format(latitude, longitude))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "map_markets = folium.Map(location=[latitude, longitude], zoom_start=10)\n\nfor lat, lng, FacilityName, borough in zip(FM_NYC_filtered['Latitude'], FM_NYC_filtered['Longitude'], FM_NYC_filtered['FacilityName'], FM_NYC_filtered['Borough']):\n            label = '{}, {}'.format(FacilityName, borough)\n            label = folium.Popup(label, parse_html=True)\n            folium.CircleMarker(\n                [lat, lng],\n                radius=5,\n                popup=label,\n                color='green',\n                fill=True,\n                fill_color='green',\n                fill_opacity=0.7,\n                parse_html = False).add_to(map_markets)  \n\nmap_markets",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.cluster import KMeans\n\nfrom sklearn.metrics import silhouette_score",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "NYC_Geo=pd.read_csv('BON1_NYC_GEO.csv')\nprint('Data downloaded!')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "NYC_Geo.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "NYC_Geo['Borough'].value_counts().to_frame()\nNYC_Geo.shape\nprint(NYC_Geo.Borough.unique())\nNYC_Geo.isnull().sum()\nBM_Geo = NYC_Geo.loc[(NYC_Geo['Borough'] == 'Brooklyn')|(NYC_Geo['Borough'] == 'Manhattan')]\nBM_Geo = BM_Geo.reset_index(drop=True)\nBM_Geo.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BM_Geo.shape",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import time\nstart_time = time.time()\n\naddress = 'New York City, NY'\n\ngeolocator = Nominatim(user_agent=\"Jupyter\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of New York City are {}, {}.'.format(latitude, longitude))\n\nprint(\"--- %s seconds ---\" % round((time.time() - start_time), 2))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "map_BM = folium.Map(location=[latitude, longitude], zoom_start=10)\n\nfor lat, lng, borough, neighborhood in zip(BM_Geo['Latitude'], BM_Geo['Longitude'], BM_Geo['Borough'], BM_Geo['Neighborhood']):\n    label = '{}, {}'.format(neighborhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_BM)  \n    \nmap_BM",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def getNearbyVenues(names, latitudes, longitudes, LIMIT=200, radius=1000):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BM_venues = getNearbyVenues(names=BM_Geo['Neighborhood'],\n                                  latitudes=BM_Geo['Latitude'],\n                                  longitudes=BM_Geo['Longitude'],\n                                  LIMIT=200)\n\nprint('The \"BM_venues\" dataframe has {} venues and {} unique venue types.'.format(\n      len(BM_venues['Venue Category']),\n      len(BM_venues['Venue Category'].unique())))\n\nBM_venues.to_csv('BM_venues.csv', sep=',', encoding='UTF8')\nBM_venues.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "colnames = ['Neighborhood', 'Neighborhood Latitude', 'Neighborhood Longitude', 'Venue', 'Venue Latitude', 'Venue Longitude', 'Venue Category']\nBM_venues = pd.read_csv('BM_venues.csv', skiprows=1, names=colnames)\nBM_venues.columns = BM_venues.columns.str.replace(' ', '')\nBM_venues.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BM_venues.shape",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def Venues_Map(Borough_name, Borough_neighborhoods):\n    \n    geolocator = Nominatim(user_agent=\"Jupyter\")\n    Borough_location = geolocator.geocode(Borough_name)\n    Borough_latitude = Borough_location.latitude\n    Borough_longitude = Borough_location.longitude\n    print('The geographical coordinates of \"{}\" are {}, {}.'.format(Borough_name, Borough_latitude, Borough_longitude))\n    \n    print('The \"{}\" dataframe has {} different venue types and {} neighborhoods.'.format(\n          Borough_name,\n          len(Borough_neighborhoods['VenueCategory'].unique()),\n          len(Borough_neighborhoods['Neighborhood'].unique())))\n    \n    map_Borough = folium.Map(location=[Borough_latitude, Borough_longitude], zoom_start=10)\n\n    for lat, lng, venue, category in zip(Borough_neighborhoods['VenueLatitude'], Borough_neighborhoods['VenueLongitude'], Borough_neighborhoods['Venue'], Borough_neighborhoods['VenueCategory']):\n        label = '{}, {}'.format(category, venue)\n        label = folium.Popup(label, parse_html=True)\n        folium.CircleMarker(\n            [lat, lng],\n            radius=0.1,\n            popup=label,\n            color='red',\n            fill=True,\n            fill_color='#FF0000',\n            fill_opacity=0.3).add_to(map_Borough)  \n\n    return map_Borough",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Venues_Map('New York City, NY', BM_venues)\nBM_venues.groupby('VenueCategory')['Venue'].count().sort_values(ascending=False)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BM_venues.groupby('Neighborhood').count()\nprint('There are {} uniques categories.'.format(len(BM_venues['VenueCategory'].unique())))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Analyzing each neighborhood..."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BM_onehot = pd.get_dummies(BM_venues[['VenueCategory']], prefix=\"\", prefix_sep=\"\")\n\ncolumn_names = ['Neighborhood'] + list(BM_onehot.columns)\n\nBM_onehot['Neighborhood'] = BM_venues['Neighborhood'] \n\nBM_onehot = BM_onehot[column_names]\n\nBM_onehot.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "restaurant_List = []\nsearch = 'Restaurant'\nfor i in BM_onehot.columns :\n    if search in i:\n        restaurant_List.append(i)\nrestaurant_List",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "col_name = []\ncol_name = ['Neighborhood'] + restaurant_List\nBM_restaurant = BM_onehot[col_name]\nBM_restaurant = BM_restaurant.iloc[:,1::]",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BM_restaurant_grouped = BM_restaurant.groupby('Neighborhood').sum().reset_index()\nBM_restaurant_grouped['Total'] = BM_restaurant_grouped .sum(axis=1)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BM_grouped_clustering = BM_restaurant_grouped.drop('Neighborhood', 1)\n\nfor n_cluster in range(2, 10):\n    kmeans = KMeans(n_clusters=n_cluster).fit(BM_grouped_clustering)\n    label = kmeans.labels_\n    sil_coeff = silhouette_score(BM_grouped_clustering, label, metric='euclidean')\n    print(\"For n_clusters={}, The Silhouette Coefficient is {}\".format(n_cluster, sil_coeff))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "kclusters = 2\n\nBM_grouped_clustering = BM_restaurant_grouped.drop('Neighborhood', 1)\n\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(BM_grouped_clustering)\n\nkmeans.labels_",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BM_results = pd.DataFrame(kmeans.cluster_centers_)\nBM_results.columns = BM_grouped_clustering.columns\nBM_results.index = ['cluster0','cluster1']\nBM_results['Total Sum'] = BM_results.sum(axis = 1)\nBM_results",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BM_results_merged = pd.DataFrame(BM_restaurant_grouped['Neighborhood'])\n\nBM_results_merged['Total'] = BM_restaurant_grouped['Total']\nBM_results_merged = BM_results_merged.assign(Cluster_Labels = kmeans.labels_)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print(BM_results_merged.shape)\nBM_results_merged\nBM_merged = BM_Geo\n\nBM_merged = BM_merged.join(BM_results_merged.set_index('Neighborhood'), on='Neighborhood')\n\nprint(BM_merged.shape)\nBM_merged.head(10)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n\nx = np.arange(kclusters)\nys = [i+x+(i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(BM_merged['Latitude'], BM_merged['Longitude'], BM_merged['Neighborhood'], BM_merged['Cluster_Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BM_merged[BM_merged['Cluster_Labels'] == 1].reset_index(drop=True)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BM_merged[BM_merged['Total'] == 0].reset_index(drop=True)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BQS_Geo = NYC_Geo.loc[(NYC_Geo['Borough'] == 'Bronx')|(NYC_Geo['Borough'] == 'Queens')|(NYC_Geo['Borough'] == 'Staten Island')]\nBQS_Geo = BQS_Geo.reset_index(drop=True)\nBQS_Geo.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BQS_Geo.shape",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "map_BQS = folium.Map(location=[latitude, longitude], zoom_start=10)\n\nfor lat, lng, borough, neighborhood in zip(BQS_Geo['Latitude'], BQS_Geo['Longitude'], BQS_Geo['Borough'], BQS_Geo['Neighborhood']):\n    label = '{}, {}'.format(neighborhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_BQS)  \n    \nmap_BQS",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BQS_venues = getNearbyVenues(names=BQS_Geo['Neighborhood'],\n                                  latitudes=BQS_Geo['Latitude'],\n                                  longitudes=BQS_Geo['Longitude'],\n                                  LIMIT=200)\n\nprint('The \"BQS_venues\" dataframe has {} venues and {} unique venue types.'.format(\n      len(BQS_venues['Venue Category']),\n      len(BQS_venues['Venue Category'].unique())))\n\nBQS_venues.to_csv('BQS_venues.csv', sep=',', encoding='UTF8')\nBQS_venues.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "colnames = ['Neighborhood', 'Neighborhood Latitude', 'Neighborhood Longitude', 'Venue', 'Venue Latitude', 'Venue Longitude', 'Venue Category']\nBQS_venues = pd.read_csv('BQS_venues.csv', skiprows=1, names=colnames)\nBQS_venues.columns = BQS_venues.columns.str.replace(' ', '')\nBQS_venues.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Venues_Map('New York City, NY', BQS_venues)\nBQS_venues.groupby('VenueCategory')['Venue'].count().sort_values(ascending=False)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BQS_venues.groupby('Neighborhood').count()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print('There are {} uniques categories.'.format(len(BQS_venues['VenueCategory'].unique())))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BQS_onehot = pd.get_dummies(BQS_venues[['VenueCategory']], prefix=\"\", prefix_sep=\"\")\n\ncolumn_names = ['Neighborhood'] + list(BQS_onehot.columns)\n\nBQS_onehot['Neighborhood'] = BQS_venues['Neighborhood'] \n\nBQS_onehot = BQS_onehot[column_names]\n\nBQS_onehot.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "restaurant_List1 = []\nsearch = 'Restaurant'\nfor i in BQS_onehot.columns :\n    if search in i:\n        restaurant_List1.append(i)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "col_name = []\ncol_name = ['Neighborhood'] + restaurant_List1\nBQS_restaurant = BQS_onehot[col_name]\nBQS_restaurant = BQS_restaurant.iloc[:,1::]",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BQS_restaurant_grouped = BQS_restaurant.groupby('Neighborhood').sum().reset_index()\n\nBQS_restaurant_grouped['Total'] = BQS_restaurant_grouped .sum(axis=1)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BQS_grouped_clustering = BQS_restaurant_grouped.drop('Neighborhood', 1)\n\nfor n_cluster in range(2, 10):\n    kmeans = KMeans(n_clusters=n_cluster).fit(BQS_grouped_clustering)\n    label = kmeans.labels_\n    sil_coeff = silhouette_score(BQS_grouped_clustering, label, metric='euclidean')\n    print(\"For n_clusters={}, The Silhouette Coefficient is {}\".format(n_cluster, sil_coeff))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "kclusters = 2\n\nBQS_grouped_clustering = BQS_restaurant_grouped.drop('Neighborhood', 1)\n\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(BQS_grouped_clustering)\n\nkmeans.labels_",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BQS_results = pd.DataFrame(kmeans.cluster_centers_)\nBQS_results.columns = BQS_grouped_clustering.columns\nBQS_results.index = ['cluster0','cluster1']\nBQS_results['Total Sum'] = BQS_results.sum(axis = 1)\nBQS_results",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BQS_results_merged = pd.DataFrame(BQS_restaurant_grouped['Neighborhood'],)\nBQS_results_merged['Total'] = BQS_restaurant_grouped['Total']\nBQS_results_merged = BQS_results_merged.assign(Cluster_Labels = kmeans.labels_)\nprint(BQS_results_merged.shape)\nBQS_results_merged",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BQS_merged = BQS_Geo\n\nBQS_merged = BQS_merged.join(BQS_results_merged.set_index('Neighborhood'), on='Neighborhood')\n\nprint(BQS_merged.shape)\nBQS_merged.head(10)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n\nx = np.arange(kclusters)\nys = [i+x+(i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(BQS_merged['Latitude'], BQS_merged['Longitude'], BQS_merged['Neighborhood'], BQS_merged['Cluster_Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BQS_merged[BQS_merged['Cluster_Labels'] == 1].reset_index(drop=True)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "BQS_merged[BQS_merged['Total'] == 0].reset_index(drop=True)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "\n# Conclusion\n### This analysis uses numerous tools to locate, gather, clean, and visualize the data from a broad range of data sources.  However, this report also does a fair job of predict the success of specific cuisines, based on the patronage of customers visiting those areas."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}